06/11 [14:16:13] [34mINFO    [39m | ]8;id=38501;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_wâ€¦]8;;\
                          >
                          >
                          [1m[
                          *
                          [1m]
                          S
                          t
                          a
                          r
                          t
                          i
                          n
                          g
                          E
                          p
                          o
                          c
                          h
                          [1m1
                          /
                          [1m3
                          [1m0
train_idx is: 0
Step 1/240, Epoch 1/30 (LogEpoch: 0), Loss: 570.8674, LR: 0.000100
global_step is: 1; target_steps is: 240
train_idx is: 1
Step 2/240, Epoch 1/30 (LogEpoch: 0), Loss: 915.5671, LR: 0.000100
global_step is: 2; target_steps is: 240
train_idx is: 2
Step 3/240, Epoch 1/30 (LogEpoch: 0), Loss: 449.8308, LR: 0.000100
global_step is: 3; target_steps is: 240
train_idx is: 3
Step 4/240, Epoch 1/30 (LogEpoch: 0), Loss: 503.2123, LR: 0.000100
global_step is: 4; target_steps is: 240
train_idx is: 4
Step 5/240, Epoch 1/30 (LogEpoch: 0), Loss: 409.8730, LR: 0.000100
global_step is: 5; target_steps is: 240
train_idx is: 5
Step 6/240, Epoch 1/30 (LogEpoch: 0), Loss: 399.4501, LR: 0.000100
global_step is: 6; target_steps is: 240
train_idx is: 6
Step 7/240, Epoch 1/30 (LogEpoch: 0), Loss: 414.9148, LR: 0.000100
global_step is: 7; target_steps is: 240
train_idx is: 7
Step 8/240, Epoch 1/30 (LogEpoch: 1), Loss: 439.5833, LR: 0.000100
global_step is: 8; target_steps is: 240
06/11 [14:20:59] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=664441;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=478509;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m0[22m. Current global_step = [1m8[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m2[22m/[1m30[22m     ]8;id=122446;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=397953;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 9/240, Epoch 2/30 (LogEpoch: 1), Loss: 386.4727, LR: 0.000100
global_step is: 9; target_steps is: 240
train_idx is: 1
Step 10/240, Epoch 2/30 (LogEpoch: 1), Loss: 453.9454, LR: 0.000100
global_step is: 10; target_steps is: 240
train_idx is: 2
Step 11/240, Epoch 2/30 (LogEpoch: 1), Loss: 470.4978, LR: 0.000100
global_step is: 11; target_steps is: 240
train_idx is: 3
Step 12/240, Epoch 2/30 (LogEpoch: 1), Loss: 378.0182, LR: 0.000100
global_step is: 12; target_steps is: 240
train_idx is: 4
Step 13/240, Epoch 2/30 (LogEpoch: 1), Loss: 411.7652, LR: 0.000100
global_step is: 13; target_steps is: 240
train_idx is: 5
Step 14/240, Epoch 2/30 (LogEpoch: 1), Loss: 341.4386, LR: 0.000100
global_step is: 14; target_steps is: 240
train_idx is: 6
Step 15/240, Epoch 2/30 (LogEpoch: 1), Loss: 351.4427, LR: 0.000100
global_step is: 15; target_steps is: 240
train_idx is: 7
Step 16/240, Epoch 2/30 (LogEpoch: 2), Loss: 335.3758, LR: 0.000100
global_step is: 16; target_steps is: 240
06/11 [14:25:26] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=742060;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=762484;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m1[22m. Current global_step = [1m16[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m3[22m/[1m30[22m     ]8;id=241755;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=6662;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 17/240, Epoch 3/30 (LogEpoch: 2), Loss: 354.0156, LR: 0.000100
global_step is: 17; target_steps is: 240
train_idx is: 1
Step 18/240, Epoch 3/30 (LogEpoch: 2), Loss: 418.5659, LR: 0.000100
global_step is: 18; target_steps is: 240
train_idx is: 2
Step 19/240, Epoch 3/30 (LogEpoch: 2), Loss: 378.3449, LR: 0.000100
global_step is: 19; target_steps is: 240
train_idx is: 3
Step 20/240, Epoch 3/30 (LogEpoch: 2), Loss: 341.4294, LR: 0.000100
global_step is: 20; target_steps is: 240
train_idx is: 4
Step 21/240, Epoch 3/30 (LogEpoch: 2), Loss: 336.3365, LR: 0.000100
global_step is: 21; target_steps is: 240
train_idx is: 5
Step 22/240, Epoch 3/30 (LogEpoch: 2), Loss: 323.5660, LR: 0.000100
global_step is: 22; target_steps is: 240
train_idx is: 6
Step 23/240, Epoch 3/30 (LogEpoch: 2), Loss: 395.3313, LR: 0.000100
global_step is: 23; target_steps is: 240
train_idx is: 7
Step 24/240, Epoch 3/30 (LogEpoch: 3), Loss: 297.5060, LR: 0.000100
global_step is: 24; target_steps is: 240
06/11 [14:29:44] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=988159;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=644973;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m2[22m. Current global_step = [1m24[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m4[22m/[1m30[22m     ]8;id=752113;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=184087;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 25/240, Epoch 4/30 (LogEpoch: 3), Loss: 284.1514, LR: 0.000100
global_step is: 25; target_steps is: 240
train_idx is: 1
Step 26/240, Epoch 4/30 (LogEpoch: 3), Loss: 301.7858, LR: 0.000100
global_step is: 26; target_steps is: 240
train_idx is: 2
Step 27/240, Epoch 4/30 (LogEpoch: 3), Loss: 380.0077, LR: 0.000100
global_step is: 27; target_steps is: 240
train_idx is: 3
Step 28/240, Epoch 4/30 (LogEpoch: 3), Loss: 238.0364, LR: 0.000100
global_step is: 28; target_steps is: 240
train_idx is: 4
Step 29/240, Epoch 4/30 (LogEpoch: 3), Loss: 322.2435, LR: 0.000100
global_step is: 29; target_steps is: 240
train_idx is: 5
Step 30/240, Epoch 4/30 (LogEpoch: 3), Loss: 266.9961, LR: 0.000100
global_step is: 30; target_steps is: 240
train_idx is: 6
Step 31/240, Epoch 4/30 (LogEpoch: 3), Loss: 311.1936, LR: 0.000100
global_step is: 31; target_steps is: 240
train_idx is: 7
Step 32/240, Epoch 4/30 (LogEpoch: 4), Loss: 299.7565, LR: 0.000100
global_step is: 32; target_steps is: 240
06/11 [14:34:06] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=349339;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=420935;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m3[22m. Current global_step = [1m32[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m5[22m/[1m30[22m     ]8;id=628270;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=310608;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 33/240, Epoch 5/30 (LogEpoch: 4), Loss: 228.3279, LR: 0.000100
global_step is: 33; target_steps is: 240
train_idx is: 1
Step 34/240, Epoch 5/30 (LogEpoch: 4), Loss: 329.6827, LR: 0.000100
global_step is: 34; target_steps is: 240
train_idx is: 2
Step 35/240, Epoch 5/30 (LogEpoch: 4), Loss: 303.1723, LR: 0.000100
global_step is: 35; target_steps is: 240
train_idx is: 3
Step 36/240, Epoch 5/30 (LogEpoch: 4), Loss: 266.7762, LR: 0.000100
global_step is: 36; target_steps is: 240
train_idx is: 4
Step 37/240, Epoch 5/30 (LogEpoch: 4), Loss: 255.2710, LR: 0.000100
global_step is: 37; target_steps is: 240
train_idx is: 5
Step 38/240, Epoch 5/30 (LogEpoch: 4), Loss: 247.8976, LR: 0.000100
global_step is: 38; target_steps is: 240
train_idx is: 6
Step 39/240, Epoch 5/30 (LogEpoch: 4), Loss: 263.4911, LR: 0.000100
global_step is: 39; target_steps is: 240
train_idx is: 7
Step 40/240, Epoch 5/30 (LogEpoch: 5), Loss: 219.5041, LR: 0.000100
global_step is: 40; target_steps is: 240
06/11 [14:38:24] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=6944;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=62567;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m4[22m. Current global_step = [1m40[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m6[22m/[1m30[22m     ]8;id=372950;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=123158;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 41/240, Epoch 6/30 (LogEpoch: 5), Loss: 254.8654, LR: 0.000100
global_step is: 41; target_steps is: 240
train_idx is: 1
Step 42/240, Epoch 6/30 (LogEpoch: 5), Loss: 213.9982, LR: 0.000100
global_step is: 42; target_steps is: 240
train_idx is: 2
Step 43/240, Epoch 6/30 (LogEpoch: 5), Loss: 222.8525, LR: 0.000100
global_step is: 43; target_steps is: 240
train_idx is: 3
Step 44/240, Epoch 6/30 (LogEpoch: 5), Loss: 232.5051, LR: 0.000100
global_step is: 44; target_steps is: 240
train_idx is: 4
Step 45/240, Epoch 6/30 (LogEpoch: 5), Loss: 245.4201, LR: 0.000100
global_step is: 45; target_steps is: 240
train_idx is: 5
Step 46/240, Epoch 6/30 (LogEpoch: 5), Loss: 220.0026, LR: 0.000100
global_step is: 46; target_steps is: 240
train_idx is: 6
Step 47/240, Epoch 6/30 (LogEpoch: 5), Loss: 302.4984, LR: 0.000100
global_step is: 47; target_steps is: 240
train_idx is: 7
Step 48/240, Epoch 6/30 (LogEpoch: 6), Loss: 201.3091, LR: 0.000100
Checkpoint saved: checkpoints_preprocessed/step-000048-epoch-06-loss=201.3091.pt
global_step is: 48; target_steps is: 240
06/11 [14:42:50] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=145735;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=417694;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m5[22m. Current global_step = [1m48[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m7[22m/[1m30[22m     ]8;id=915036;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=567017;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 49/240, Epoch 7/30 (LogEpoch: 6), Loss: 236.6503, LR: 0.000100
global_step is: 49; target_steps is: 240
train_idx is: 1
Step 50/240, Epoch 7/30 (LogEpoch: 6), Loss: 214.3429, LR: 0.000100
global_step is: 50; target_steps is: 240
train_idx is: 2
Step 51/240, Epoch 7/30 (LogEpoch: 6), Loss: 213.6273, LR: 0.000100
global_step is: 51; target_steps is: 240
train_idx is: 3
Step 52/240, Epoch 7/30 (LogEpoch: 6), Loss: 209.7149, LR: 0.000100
global_step is: 52; target_steps is: 240
train_idx is: 4
Step 53/240, Epoch 7/30 (LogEpoch: 6), Loss: 295.7134, LR: 0.000100
global_step is: 53; target_steps is: 240
train_idx is: 5
Step 54/240, Epoch 7/30 (LogEpoch: 6), Loss: 218.7569, LR: 0.000100
global_step is: 54; target_steps is: 240
train_idx is: 6
Step 55/240, Epoch 7/30 (LogEpoch: 6), Loss: 198.4651, LR: 0.000100
global_step is: 55; target_steps is: 240
train_idx is: 7
Step 56/240, Epoch 7/30 (LogEpoch: 7), Loss: 198.4049, LR: 0.000100
global_step is: 56; target_steps is: 240
06/11 [14:47:04] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=637621;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=935656;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m6[22m. Current global_step = [1m56[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m8[22m/[1m30[22m     ]8;id=419959;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=356954;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 57/240, Epoch 8/30 (LogEpoch: 7), Loss: 173.8048, LR: 0.000100
global_step is: 57; target_steps is: 240
train_idx is: 1
Step 58/240, Epoch 8/30 (LogEpoch: 7), Loss: 210.6066, LR: 0.000100
global_step is: 58; target_steps is: 240
train_idx is: 2
Step 59/240, Epoch 8/30 (LogEpoch: 7), Loss: 193.7930, LR: 0.000100
global_step is: 59; target_steps is: 240
train_idx is: 3
Step 60/240, Epoch 8/30 (LogEpoch: 7), Loss: 164.3458, LR: 0.000100
global_step is: 60; target_steps is: 240
train_idx is: 4
Step 61/240, Epoch 8/30 (LogEpoch: 7), Loss: 217.7860, LR: 0.000100
global_step is: 61; target_steps is: 240
train_idx is: 5
Step 62/240, Epoch 8/30 (LogEpoch: 7), Loss: 206.6857, LR: 0.000100
global_step is: 62; target_steps is: 240
train_idx is: 6
Step 63/240, Epoch 8/30 (LogEpoch: 7), Loss: 198.5639, LR: 0.000100
global_step is: 63; target_steps is: 240
train_idx is: 7
Step 64/240, Epoch 8/30 (LogEpoch: 8), Loss: 254.7661, LR: 0.000100
global_step is: 64; target_steps is: 240
06/11 [14:51:22] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=653342;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=622550;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m7[22m. Current global_step = [1m64[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m9[22m/[1m30[22m     ]8;id=351753;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=148975;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 65/240, Epoch 9/30 (LogEpoch: 8), Loss: 189.9083, LR: 0.000100
global_step is: 65; target_steps is: 240
train_idx is: 1
Step 66/240, Epoch 9/30 (LogEpoch: 8), Loss: 188.6286, LR: 0.000100
global_step is: 66; target_steps is: 240
train_idx is: 2
Step 67/240, Epoch 9/30 (LogEpoch: 8), Loss: 165.0806, LR: 0.000100
global_step is: 67; target_steps is: 240
train_idx is: 3
Step 68/240, Epoch 9/30 (LogEpoch: 8), Loss: 180.2071, LR: 0.000100
global_step is: 68; target_steps is: 240
train_idx is: 4
Step 69/240, Epoch 9/30 (LogEpoch: 8), Loss: 157.9160, LR: 0.000100
global_step is: 69; target_steps is: 240
train_idx is: 5
Step 70/240, Epoch 9/30 (LogEpoch: 8), Loss: 159.6105, LR: 0.000100
global_step is: 70; target_steps is: 240
train_idx is: 6
Step 71/240, Epoch 9/30 (LogEpoch: 8), Loss: 146.6684, LR: 0.000100
global_step is: 71; target_steps is: 240
train_idx is: 7
Step 72/240, Epoch 9/30 (LogEpoch: 9), Loss: 148.8756, LR: 0.000100
global_step is: 72; target_steps is: 240
06/11 [14:55:44] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=680794;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=455205;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m8[22m. Current global_step = [1m72[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m10[22m/[1m30[22m    ]8;id=408979;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=570774;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 73/240, Epoch 10/30 (LogEpoch: 9), Loss: 178.5881, LR: 0.000100
global_step is: 73; target_steps is: 240
train_idx is: 1
Step 74/240, Epoch 10/30 (LogEpoch: 9), Loss: 172.1983, LR: 0.000100
global_step is: 74; target_steps is: 240
train_idx is: 2
Step 75/240, Epoch 10/30 (LogEpoch: 9), Loss: 163.2068, LR: 0.000100
global_step is: 75; target_steps is: 240
train_idx is: 3
Step 76/240, Epoch 10/30 (LogEpoch: 9), Loss: 148.9727, LR: 0.000100
global_step is: 76; target_steps is: 240
train_idx is: 4
Step 77/240, Epoch 10/30 (LogEpoch: 9), Loss: 132.2353, LR: 0.000100
global_step is: 77; target_steps is: 240
train_idx is: 5
Step 78/240, Epoch 10/30 (LogEpoch: 9), Loss: 160.9904, LR: 0.000100
global_step is: 78; target_steps is: 240
train_idx is: 6
Step 79/240, Epoch 10/30 (LogEpoch: 9), Loss: 143.8661, LR: 0.000100
global_step is: 79; target_steps is: 240
train_idx is: 7
Step 80/240, Epoch 10/30 (LogEpoch: 10), Loss: 182.4116, LR: 0.000100
global_step is: 80; target_steps is: 240
06/11 [15:00:04] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=879287;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=681577;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m9[22m. Current global_step = [1m80[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m11[22m/[1m30[22m    ]8;id=962523;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=464611;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 81/240, Epoch 11/30 (LogEpoch: 10), Loss: 151.6182, LR: 0.000100
global_step is: 81; target_steps is: 240
train_idx is: 1
Step 82/240, Epoch 11/30 (LogEpoch: 10), Loss: 147.5919, LR: 0.000100
global_step is: 82; target_steps is: 240
train_idx is: 2
Step 83/240, Epoch 11/30 (LogEpoch: 10), Loss: 125.8758, LR: 0.000100
global_step is: 83; target_steps is: 240
train_idx is: 3
Step 84/240, Epoch 11/30 (LogEpoch: 10), Loss: 132.8501, LR: 0.000100
global_step is: 84; target_steps is: 240
train_idx is: 4
Step 85/240, Epoch 11/30 (LogEpoch: 10), Loss: 186.8390, LR: 0.000100
global_step is: 85; target_steps is: 240
train_idx is: 5
Step 86/240, Epoch 11/30 (LogEpoch: 10), Loss: 130.6211, LR: 0.000100
global_step is: 86; target_steps is: 240
train_idx is: 6
Step 87/240, Epoch 11/30 (LogEpoch: 10), Loss: 142.8983, LR: 0.000100
global_step is: 87; target_steps is: 240
train_idx is: 7
Step 88/240, Epoch 11/30 (LogEpoch: 11), Loss: 137.5791, LR: 0.000100
global_step is: 88; target_steps is: 240
06/11 [15:04:25] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=794232;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=340423;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m10[22m. Current global_step = [1m88[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m12[22m/[1m30[22m    ]8;id=472428;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=254529;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 89/240, Epoch 12/30 (LogEpoch: 11), Loss: 135.9441, LR: 0.000100
global_step is: 89; target_steps is: 240
train_idx is: 1
Step 90/240, Epoch 12/30 (LogEpoch: 11), Loss: 133.3873, LR: 0.000100
global_step is: 90; target_steps is: 240
train_idx is: 2
Step 91/240, Epoch 12/30 (LogEpoch: 11), Loss: 143.9393, LR: 0.000100
global_step is: 91; target_steps is: 240
train_idx is: 3
Step 92/240, Epoch 12/30 (LogEpoch: 11), Loss: 126.3061, LR: 0.000100
global_step is: 92; target_steps is: 240
train_idx is: 4
Step 93/240, Epoch 12/30 (LogEpoch: 11), Loss: 127.1918, LR: 0.000100
global_step is: 93; target_steps is: 240
train_idx is: 5
Step 94/240, Epoch 12/30 (LogEpoch: 11), Loss: 124.0830, LR: 0.000100
global_step is: 94; target_steps is: 240
train_idx is: 6
Step 95/240, Epoch 12/30 (LogEpoch: 11), Loss: 115.8204, LR: 0.000100
global_step is: 95; target_steps is: 240
train_idx is: 7
Step 96/240, Epoch 12/30 (LogEpoch: 12), Loss: 129.2490, LR: 0.000100
Checkpoint saved: checkpoints_preprocessed/step-000096-epoch-12-loss=129.2490.pt
global_step is: 96; target_steps is: 240
06/11 [15:08:49] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=265416;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=470782;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m11[22m. Current global_step = [1m96[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m13[22m/[1m30[22m    ]8;id=86572;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=202073;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 97/240, Epoch 13/30 (LogEpoch: 12), Loss: 133.9963, LR: 0.000100
global_step is: 97; target_steps is: 240
train_idx is: 1
Step 98/240, Epoch 13/30 (LogEpoch: 12), Loss: 120.3730, LR: 0.000100
global_step is: 98; target_steps is: 240
train_idx is: 2
Step 99/240, Epoch 13/30 (LogEpoch: 12), Loss: 124.2970, LR: 0.000100
global_step is: 99; target_steps is: 240
train_idx is: 3
Step 100/240, Epoch 13/30 (LogEpoch: 12), Loss: 118.7383, LR: 0.000100
global_step is: 100; target_steps is: 240
train_idx is: 4
Step 101/240, Epoch 13/30 (LogEpoch: 12), Loss: 135.7532, LR: 0.000100
global_step is: 101; target_steps is: 240
train_idx is: 5
Step 102/240, Epoch 13/30 (LogEpoch: 12), Loss: 122.7219, LR: 0.000100
global_step is: 102; target_steps is: 240
train_idx is: 6
Step 103/240, Epoch 13/30 (LogEpoch: 12), Loss: 139.8080, LR: 0.000100
global_step is: 103; target_steps is: 240
train_idx is: 7
Step 104/240, Epoch 13/30 (LogEpoch: 13), Loss: 115.5055, LR: 0.000100
global_step is: 104; target_steps is: 240
06/11 [15:13:03] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=253102;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=247063;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m12[22m. Current global_step = [1m104[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m14[22m/[1m30[22m    ]8;id=460564;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=503955;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 105/240, Epoch 14/30 (LogEpoch: 13), Loss: 115.7079, LR: 0.000100
global_step is: 105; target_steps is: 240
train_idx is: 1
Step 106/240, Epoch 14/30 (LogEpoch: 13), Loss: 151.4301, LR: 0.000100
global_step is: 106; target_steps is: 240
train_idx is: 2
Step 107/240, Epoch 14/30 (LogEpoch: 13), Loss: 113.8900, LR: 0.000100
global_step is: 107; target_steps is: 240
train_idx is: 3
Step 108/240, Epoch 14/30 (LogEpoch: 13), Loss: 117.3715, LR: 0.000100
global_step is: 108; target_steps is: 240
train_idx is: 4
Step 109/240, Epoch 14/30 (LogEpoch: 13), Loss: 129.3631, LR: 0.000100
global_step is: 109; target_steps is: 240
train_idx is: 5
Step 110/240, Epoch 14/30 (LogEpoch: 13), Loss: 116.4371, LR: 0.000100
global_step is: 110; target_steps is: 240
train_idx is: 6
Step 111/240, Epoch 14/30 (LogEpoch: 13), Loss: 122.1324, LR: 0.000100
global_step is: 111; target_steps is: 240
train_idx is: 7
Step 112/240, Epoch 14/30 (LogEpoch: 14), Loss: 148.9078, LR: 0.000100
global_step is: 112; target_steps is: 240
06/11 [15:17:21] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=143420;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=792549;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m13[22m. Current global_step = [1m112[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m15[22m/[1m30[22m    ]8;id=10936;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=558832;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 113/240, Epoch 15/30 (LogEpoch: 14), Loss: 127.9480, LR: 0.000100
global_step is: 113; target_steps is: 240
train_idx is: 1
Step 114/240, Epoch 15/30 (LogEpoch: 14), Loss: 108.7805, LR: 0.000100
global_step is: 114; target_steps is: 240
train_idx is: 2
Step 115/240, Epoch 15/30 (LogEpoch: 14), Loss: 102.5714, LR: 0.000100
global_step is: 115; target_steps is: 240
train_idx is: 3
Step 116/240, Epoch 15/30 (LogEpoch: 14), Loss: 101.6978, LR: 0.000100
global_step is: 116; target_steps is: 240
train_idx is: 4
Step 117/240, Epoch 15/30 (LogEpoch: 14), Loss: 96.9159, LR: 0.000100
global_step is: 117; target_steps is: 240
train_idx is: 5
Step 118/240, Epoch 15/30 (LogEpoch: 14), Loss: 102.8058, LR: 0.000100
global_step is: 118; target_steps is: 240
train_idx is: 6
Step 119/240, Epoch 15/30 (LogEpoch: 14), Loss: 96.0719, LR: 0.000100
global_step is: 119; target_steps is: 240
train_idx is: 7
Step 120/240, Epoch 15/30 (LogEpoch: 15), Loss: 151.1403, LR: 0.000100
global_step is: 120; target_steps is: 240
06/11 [15:21:47] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=242160;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=878237;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m14[22m. Current global_step = [1m120[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m16[22m/[1m30[22m    ]8;id=184082;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=216434;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 121/240, Epoch 16/30 (LogEpoch: 15), Loss: 150.7101, LR: 0.000100
global_step is: 121; target_steps is: 240
train_idx is: 1
Step 122/240, Epoch 16/30 (LogEpoch: 15), Loss: 101.2597, LR: 0.000100
global_step is: 122; target_steps is: 240
train_idx is: 2
Step 123/240, Epoch 16/30 (LogEpoch: 15), Loss: 96.5232, LR: 0.000100
global_step is: 123; target_steps is: 240
train_idx is: 3
Step 124/240, Epoch 16/30 (LogEpoch: 15), Loss: 99.3840, LR: 0.000100
global_step is: 124; target_steps is: 240
train_idx is: 4
Step 125/240, Epoch 16/30 (LogEpoch: 15), Loss: 98.7912, LR: 0.000100
global_step is: 125; target_steps is: 240
train_idx is: 5
Step 126/240, Epoch 16/30 (LogEpoch: 15), Loss: 94.9497, LR: 0.000100
global_step is: 126; target_steps is: 240
train_idx is: 6
Step 127/240, Epoch 16/30 (LogEpoch: 15), Loss: 98.5634, LR: 0.000100
global_step is: 127; target_steps is: 240
train_idx is: 7
Step 128/240, Epoch 16/30 (LogEpoch: 16), Loss: 95.5711, LR: 0.000100
global_step is: 128; target_steps is: 240
06/11 [15:26:03] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=400501;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=133347;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m15[22m. Current global_step = [1m128[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m17[22m/[1m30[22m    ]8;id=892035;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=55152;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 129/240, Epoch 17/30 (LogEpoch: 16), Loss: 101.5325, LR: 0.000100
global_step is: 129; target_steps is: 240
train_idx is: 1
Step 130/240, Epoch 17/30 (LogEpoch: 16), Loss: 91.6225, LR: 0.000100
global_step is: 130; target_steps is: 240
train_idx is: 2
Step 131/240, Epoch 17/30 (LogEpoch: 16), Loss: 98.9059, LR: 0.000100
global_step is: 131; target_steps is: 240
train_idx is: 3
Step 132/240, Epoch 17/30 (LogEpoch: 16), Loss: 94.0119, LR: 0.000100
global_step is: 132; target_steps is: 240
train_idx is: 4
Step 133/240, Epoch 17/30 (LogEpoch: 16), Loss: 96.9537, LR: 0.000100
global_step is: 133; target_steps is: 240
train_idx is: 5
Step 134/240, Epoch 17/30 (LogEpoch: 16), Loss: 84.9670, LR: 0.000100
global_step is: 134; target_steps is: 240
train_idx is: 6
Step 135/240, Epoch 17/30 (LogEpoch: 16), Loss: 83.8648, LR: 0.000100
global_step is: 135; target_steps is: 240
train_idx is: 7
Step 136/240, Epoch 17/30 (LogEpoch: 17), Loss: 188.6957, LR: 0.000100
global_step is: 136; target_steps is: 240
06/11 [15:30:16] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=719235;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=315990;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m16[22m. Current global_step = [1m136[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m18[22m/[1m30[22m    ]8;id=831224;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=947678;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 137/240, Epoch 18/30 (LogEpoch: 17), Loss: 93.9650, LR: 0.000100
global_step is: 137; target_steps is: 240
train_idx is: 1
Step 138/240, Epoch 18/30 (LogEpoch: 17), Loss: 89.3470, LR: 0.000100
global_step is: 138; target_steps is: 240
train_idx is: 2
Step 139/240, Epoch 18/30 (LogEpoch: 17), Loss: 85.9014, LR: 0.000100
global_step is: 139; target_steps is: 240
train_idx is: 3
Step 140/240, Epoch 18/30 (LogEpoch: 17), Loss: 78.7400, LR: 0.000100
global_step is: 140; target_steps is: 240
train_idx is: 4
Step 141/240, Epoch 18/30 (LogEpoch: 17), Loss: 85.9260, LR: 0.000100
global_step is: 141; target_steps is: 240
train_idx is: 5
Step 142/240, Epoch 18/30 (LogEpoch: 17), Loss: 84.1311, LR: 0.000100
global_step is: 142; target_steps is: 240
train_idx is: 6
Step 143/240, Epoch 18/30 (LogEpoch: 17), Loss: 110.5149, LR: 0.000100
global_step is: 143; target_steps is: 240
train_idx is: 7
Step 144/240, Epoch 18/30 (LogEpoch: 18), Loss: 92.5764, LR: 0.000100
Checkpoint saved: checkpoints_preprocessed/step-000144-epoch-18-loss=92.5764.pt
global_step is: 144; target_steps is: 240
06/11 [15:34:44] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=607644;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=130478;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m17[22m. Current global_step = [1m144[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m19[22m/[1m30[22m    ]8;id=532316;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=11567;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 145/240, Epoch 19/30 (LogEpoch: 18), Loss: 90.4999, LR: 0.000100
global_step is: 145; target_steps is: 240
train_idx is: 1
Step 146/240, Epoch 19/30 (LogEpoch: 18), Loss: 85.4689, LR: 0.000100
global_step is: 146; target_steps is: 240
train_idx is: 2
Step 147/240, Epoch 19/30 (LogEpoch: 18), Loss: 75.0199, LR: 0.000100
global_step is: 147; target_steps is: 240
train_idx is: 3
Step 148/240, Epoch 19/30 (LogEpoch: 18), Loss: 93.7563, LR: 0.000100
global_step is: 148; target_steps is: 240
train_idx is: 4
Step 149/240, Epoch 19/30 (LogEpoch: 18), Loss: 83.2691, LR: 0.000100
global_step is: 149; target_steps is: 240
train_idx is: 5
Step 150/240, Epoch 19/30 (LogEpoch: 18), Loss: 99.5719, LR: 0.000100
global_step is: 150; target_steps is: 240
train_idx is: 6
Step 151/240, Epoch 19/30 (LogEpoch: 18), Loss: 89.6534, LR: 0.000100
global_step is: 151; target_steps is: 240
train_idx is: 7
Step 152/240, Epoch 19/30 (LogEpoch: 19), Loss: 129.6445, LR: 0.000100
global_step is: 152; target_steps is: 240
06/11 [15:39:03] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=35029;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=708923;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m18[22m. Current global_step = [1m152[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m20[22m/[1m30[22m    ]8;id=19435;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=562786;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 153/240, Epoch 20/30 (LogEpoch: 19), Loss: 86.1240, LR: 0.000100
global_step is: 153; target_steps is: 240
train_idx is: 1
Step 154/240, Epoch 20/30 (LogEpoch: 19), Loss: 91.0356, LR: 0.000100
global_step is: 154; target_steps is: 240
train_idx is: 2
Step 155/240, Epoch 20/30 (LogEpoch: 19), Loss: 82.0455, LR: 0.000100
global_step is: 155; target_steps is: 240
train_idx is: 3
Step 156/240, Epoch 20/30 (LogEpoch: 19), Loss: 92.8437, LR: 0.000100
global_step is: 156; target_steps is: 240
train_idx is: 4
Step 157/240, Epoch 20/30 (LogEpoch: 19), Loss: 82.9618, LR: 0.000100
global_step is: 157; target_steps is: 240
train_idx is: 5
Step 158/240, Epoch 20/30 (LogEpoch: 19), Loss: 86.7740, LR: 0.000100
global_step is: 158; target_steps is: 240
train_idx is: 6
Step 159/240, Epoch 20/30 (LogEpoch: 19), Loss: 85.4099, LR: 0.000100
global_step is: 159; target_steps is: 240
train_idx is: 7
Step 160/240, Epoch 20/30 (LogEpoch: 20), Loss: 84.0833, LR: 0.000100
global_step is: 160; target_steps is: 240
06/11 [15:43:26] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=981789;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=493463;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m19[22m. Current global_step = [1m160[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m21[22m/[1m30[22m    ]8;id=32408;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=121862;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 161/240, Epoch 21/30 (LogEpoch: 20), Loss: 87.3491, LR: 0.000100
global_step is: 161; target_steps is: 240
train_idx is: 1
Step 162/240, Epoch 21/30 (LogEpoch: 20), Loss: 82.2928, LR: 0.000100
global_step is: 162; target_steps is: 240
train_idx is: 2
Step 163/240, Epoch 21/30 (LogEpoch: 20), Loss: 81.8321, LR: 0.000100
global_step is: 163; target_steps is: 240
train_idx is: 3
Step 164/240, Epoch 21/30 (LogEpoch: 20), Loss: 72.2099, LR: 0.000100
global_step is: 164; target_steps is: 240
train_idx is: 4
Step 165/240, Epoch 21/30 (LogEpoch: 20), Loss: 79.7765, LR: 0.000100
global_step is: 165; target_steps is: 240
train_idx is: 5
Step 166/240, Epoch 21/30 (LogEpoch: 20), Loss: 77.0508, LR: 0.000100
global_step is: 166; target_steps is: 240
train_idx is: 6
Step 167/240, Epoch 21/30 (LogEpoch: 20), Loss: 71.5562, LR: 0.000100
global_step is: 167; target_steps is: 240
train_idx is: 7
Step 168/240, Epoch 21/30 (LogEpoch: 21), Loss: 80.2067, LR: 0.000100
global_step is: 168; target_steps is: 240
06/11 [15:47:50] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=148467;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=141469;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m20[22m. Current global_step = [1m168[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m22[22m/[1m30[22m    ]8;id=519060;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=278178;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 169/240, Epoch 22/30 (LogEpoch: 21), Loss: 73.1244, LR: 0.000100
global_step is: 169; target_steps is: 240
train_idx is: 1
Step 170/240, Epoch 22/30 (LogEpoch: 21), Loss: 78.9495, LR: 0.000100
global_step is: 170; target_steps is: 240
train_idx is: 2
Step 171/240, Epoch 22/30 (LogEpoch: 21), Loss: 89.6726, LR: 0.000100
global_step is: 171; target_steps is: 240
train_idx is: 3
Step 172/240, Epoch 22/30 (LogEpoch: 21), Loss: 83.2191, LR: 0.000100
global_step is: 172; target_steps is: 240
train_idx is: 4
Step 173/240, Epoch 22/30 (LogEpoch: 21), Loss: 78.5574, LR: 0.000100
global_step is: 173; target_steps is: 240
train_idx is: 5
Step 174/240, Epoch 22/30 (LogEpoch: 21), Loss: 70.5380, LR: 0.000100
global_step is: 174; target_steps is: 240
train_idx is: 6
Step 175/240, Epoch 22/30 (LogEpoch: 21), Loss: 86.7085, LR: 0.000100
global_step is: 175; target_steps is: 240
train_idx is: 7
Step 176/240, Epoch 22/30 (LogEpoch: 22), Loss: 74.9050, LR: 0.000100
global_step is: 176; target_steps is: 240
06/11 [15:52:08] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=1567;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=728652;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m21[22m. Current global_step = [1m176[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m23[22m/[1m30[22m    ]8;id=960806;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=597969;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 177/240, Epoch 23/30 (LogEpoch: 22), Loss: 116.2377, LR: 0.000100
global_step is: 177; target_steps is: 240
train_idx is: 1
Step 178/240, Epoch 23/30 (LogEpoch: 22), Loss: 75.7862, LR: 0.000100
global_step is: 178; target_steps is: 240
train_idx is: 2
Step 179/240, Epoch 23/30 (LogEpoch: 22), Loss: 89.1248, LR: 0.000100
global_step is: 179; target_steps is: 240
train_idx is: 3
Step 180/240, Epoch 23/30 (LogEpoch: 22), Loss: 65.8950, LR: 0.000100
global_step is: 180; target_steps is: 240
train_idx is: 4
Step 181/240, Epoch 23/30 (LogEpoch: 22), Loss: 77.6312, LR: 0.000100
global_step is: 181; target_steps is: 240
train_idx is: 5
Step 182/240, Epoch 23/30 (LogEpoch: 22), Loss: 65.3033, LR: 0.000100
global_step is: 182; target_steps is: 240
train_idx is: 6
Step 183/240, Epoch 23/30 (LogEpoch: 22), Loss: 78.2783, LR: 0.000100
global_step is: 183; target_steps is: 240
train_idx is: 7
Step 184/240, Epoch 23/30 (LogEpoch: 23), Loss: 82.3860, LR: 0.000100
global_step is: 184; target_steps is: 240
06/11 [15:56:26] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=912040;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=565644;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m22[22m. Current global_step = [1m184[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m24[22m/[1m30[22m    ]8;id=344328;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=751810;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 185/240, Epoch 24/30 (LogEpoch: 23), Loss: 80.2220, LR: 0.000100
global_step is: 185; target_steps is: 240
train_idx is: 1
Step 186/240, Epoch 24/30 (LogEpoch: 23), Loss: 74.8855, LR: 0.000100
global_step is: 186; target_steps is: 240
train_idx is: 2
Step 187/240, Epoch 24/30 (LogEpoch: 23), Loss: 76.4266, LR: 0.000100
global_step is: 187; target_steps is: 240
train_idx is: 3
Step 188/240, Epoch 24/30 (LogEpoch: 23), Loss: 77.5416, LR: 0.000100
global_step is: 188; target_steps is: 240
train_idx is: 4
Step 189/240, Epoch 24/30 (LogEpoch: 23), Loss: 78.5394, LR: 0.000100
global_step is: 189; target_steps is: 240
train_idx is: 5
Step 190/240, Epoch 24/30 (LogEpoch: 23), Loss: 69.7845, LR: 0.000100
global_step is: 190; target_steps is: 240
train_idx is: 6
Step 191/240, Epoch 24/30 (LogEpoch: 23), Loss: 109.7390, LR: 0.000100
global_step is: 191; target_steps is: 240
train_idx is: 7
Step 192/240, Epoch 24/30 (LogEpoch: 24), Loss: 73.6624, LR: 0.000100
Checkpoint saved: checkpoints_preprocessed/step-000192-epoch-24-loss=73.6624.pt
global_step is: 192; target_steps is: 240
06/11 [16:00:47] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=350294;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=138068;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m23[22m. Current global_step = [1m192[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m25[22m/[1m30[22m    ]8;id=413434;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=942802;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 193/240, Epoch 25/30 (LogEpoch: 24), Loss: 72.6749, LR: 0.000100
global_step is: 193; target_steps is: 240
train_idx is: 1
Step 194/240, Epoch 25/30 (LogEpoch: 24), Loss: 73.4245, LR: 0.000100
global_step is: 194; target_steps is: 240
train_idx is: 2
Step 195/240, Epoch 25/30 (LogEpoch: 24), Loss: 65.4431, LR: 0.000100
global_step is: 195; target_steps is: 240
train_idx is: 3
Step 196/240, Epoch 25/30 (LogEpoch: 24), Loss: 66.6047, LR: 0.000100
global_step is: 196; target_steps is: 240
train_idx is: 4
Step 197/240, Epoch 25/30 (LogEpoch: 24), Loss: 62.7625, LR: 0.000100
global_step is: 197; target_steps is: 240
train_idx is: 5
Step 198/240, Epoch 25/30 (LogEpoch: 24), Loss: 66.3496, LR: 0.000100
global_step is: 198; target_steps is: 240
train_idx is: 6
Step 199/240, Epoch 25/30 (LogEpoch: 24), Loss: 69.1579, LR: 0.000100
global_step is: 199; target_steps is: 240
train_idx is: 7
Step 200/240, Epoch 25/30 (LogEpoch: 25), Loss: 62.4233, LR: 0.000100
global_step is: 200; target_steps is: 240
06/11 [16:05:01] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=395029;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=229952;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m24[22m. Current global_step = [1m200[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m26[22m/[1m30[22m    ]8;id=936812;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=903161;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 201/240, Epoch 26/30 (LogEpoch: 25), Loss: 64.1087, LR: 0.000100
global_step is: 201; target_steps is: 240
train_idx is: 1
Step 202/240, Epoch 26/30 (LogEpoch: 25), Loss: 74.6961, LR: 0.000100
global_step is: 202; target_steps is: 240
train_idx is: 2
Step 203/240, Epoch 26/30 (LogEpoch: 25), Loss: 69.3438, LR: 0.000100
global_step is: 203; target_steps is: 240
train_idx is: 3
Step 204/240, Epoch 26/30 (LogEpoch: 25), Loss: 64.1195, LR: 0.000100
global_step is: 204; target_steps is: 240
train_idx is: 4
Step 205/240, Epoch 26/30 (LogEpoch: 25), Loss: 75.8699, LR: 0.000100
global_step is: 205; target_steps is: 240
train_idx is: 5
Step 206/240, Epoch 26/30 (LogEpoch: 25), Loss: 62.9929, LR: 0.000100
global_step is: 206; target_steps is: 240
train_idx is: 6
Step 207/240, Epoch 26/30 (LogEpoch: 25), Loss: 65.6630, LR: 0.000100
global_step is: 207; target_steps is: 240
train_idx is: 7
Step 208/240, Epoch 26/30 (LogEpoch: 26), Loss: 108.5665, LR: 0.000100
global_step is: 208; target_steps is: 240
06/11 [16:09:15] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=572100;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=831922;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m25[22m. Current global_step = [1m208[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m27[22m/[1m30[22m    ]8;id=595076;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=174975;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 209/240, Epoch 27/30 (LogEpoch: 26), Loss: 70.3270, LR: 0.000100
global_step is: 209; target_steps is: 240
train_idx is: 1
Step 210/240, Epoch 27/30 (LogEpoch: 26), Loss: 75.4943, LR: 0.000100
global_step is: 210; target_steps is: 240
train_idx is: 2
Step 211/240, Epoch 27/30 (LogEpoch: 26), Loss: 69.6821, LR: 0.000100
global_step is: 211; target_steps is: 240
train_idx is: 3
Step 212/240, Epoch 27/30 (LogEpoch: 26), Loss: 60.4722, LR: 0.000100
global_step is: 212; target_steps is: 240
train_idx is: 4
Step 213/240, Epoch 27/30 (LogEpoch: 26), Loss: 97.7654, LR: 0.000100
global_step is: 213; target_steps is: 240
train_idx is: 5
Step 214/240, Epoch 27/30 (LogEpoch: 26), Loss: 61.7158, LR: 0.000100
global_step is: 214; target_steps is: 240
train_idx is: 6
Step 215/240, Epoch 27/30 (LogEpoch: 26), Loss: 73.6792, LR: 0.000100
global_step is: 215; target_steps is: 240
train_idx is: 7
Step 216/240, Epoch 27/30 (LogEpoch: 27), Loss: 84.0945, LR: 0.000100
global_step is: 216; target_steps is: 240
06/11 [16:13:34] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=990261;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=303399;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m26[22m. Current global_step = [1m216[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m28[22m/[1m30[22m    ]8;id=796862;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=420990;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 217/240, Epoch 28/30 (LogEpoch: 27), Loss: 57.6277, LR: 0.000100
global_step is: 217; target_steps is: 240
train_idx is: 1
Step 218/240, Epoch 28/30 (LogEpoch: 27), Loss: 72.6257, LR: 0.000100
global_step is: 218; target_steps is: 240
train_idx is: 2
Step 219/240, Epoch 28/30 (LogEpoch: 27), Loss: 60.8421, LR: 0.000100
global_step is: 219; target_steps is: 240
train_idx is: 3
Step 220/240, Epoch 28/30 (LogEpoch: 27), Loss: 57.8658, LR: 0.000100
global_step is: 220; target_steps is: 240
train_idx is: 4
Step 221/240, Epoch 28/30 (LogEpoch: 27), Loss: 63.5723, LR: 0.000100
global_step is: 221; target_steps is: 240
train_idx is: 5
Step 222/240, Epoch 28/30 (LogEpoch: 27), Loss: 68.8799, LR: 0.000100
global_step is: 222; target_steps is: 240
train_idx is: 6
Step 223/240, Epoch 28/30 (LogEpoch: 27), Loss: 65.3256, LR: 0.000100
global_step is: 223; target_steps is: 240
train_idx is: 7
Step 224/240, Epoch 28/30 (LogEpoch: 28), Loss: 57.6919, LR: 0.000100
global_step is: 224; target_steps is: 240
06/11 [16:17:54] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=25172;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=977716;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m27[22m. Current global_step = [1m224[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m29[22m/[1m30[22m    ]8;id=43460;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=719684;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 225/240, Epoch 29/30 (LogEpoch: 28), Loss: 58.3096, LR: 0.000100
global_step is: 225; target_steps is: 240
train_idx is: 1
Step 226/240, Epoch 29/30 (LogEpoch: 28), Loss: 68.8256, LR: 0.000100
global_step is: 226; target_steps is: 240
train_idx is: 2
Step 227/240, Epoch 29/30 (LogEpoch: 28), Loss: 63.6765, LR: 0.000100
global_step is: 227; target_steps is: 240
train_idx is: 3
Step 228/240, Epoch 29/30 (LogEpoch: 28), Loss: 59.8210, LR: 0.000100
global_step is: 228; target_steps is: 240
train_idx is: 4
Step 229/240, Epoch 29/30 (LogEpoch: 28), Loss: 64.9094, LR: 0.000100
global_step is: 229; target_steps is: 240
train_idx is: 5
Step 230/240, Epoch 29/30 (LogEpoch: 28), Loss: 68.9408, LR: 0.000100
global_step is: 230; target_steps is: 240
train_idx is: 6
Step 231/240, Epoch 29/30 (LogEpoch: 28), Loss: 101.0570, LR: 0.000100
global_step is: 231; target_steps is: 240
train_idx is: 7
Step 232/240, Epoch 29/30 (LogEpoch: 29), Loss: 57.8410, LR: 0.000100
global_step is: 232; target_steps is: 240
06/11 [16:22:11] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=354878;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=78961;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m28[22m. Current global_step = [1m232[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Starting Epoch [1m30[22m/[1m30[22m    ]8;id=317212;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=603003;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#254\254]8;;\
train_idx is: 0
Step 233/240, Epoch 30/30 (LogEpoch: 29), Loss: 67.0840, LR: 0.000100
global_step is: 233; target_steps is: 240
train_idx is: 1
Step 234/240, Epoch 30/30 (LogEpoch: 29), Loss: 65.0450, LR: 0.000100
global_step is: 234; target_steps is: 240
train_idx is: 2
Step 235/240, Epoch 30/30 (LogEpoch: 29), Loss: 64.5183, LR: 0.000100
global_step is: 235; target_steps is: 240
train_idx is: 3
Step 236/240, Epoch 30/30 (LogEpoch: 29), Loss: 56.8132, LR: 0.000100
global_step is: 236; target_steps is: 240
train_idx is: 4
Step 237/240, Epoch 30/30 (LogEpoch: 29), Loss: 62.0176, LR: 0.000100
global_step is: 237; target_steps is: 240
train_idx is: 5
Step 238/240, Epoch 30/30 (LogEpoch: 29), Loss: 63.1171, LR: 0.000100
global_step is: 238; target_steps is: 240
train_idx is: 6
Step 239/240, Epoch 30/30 (LogEpoch: 29), Loss: 62.7904, LR: 0.000100
global_step is: 239; target_steps is: 240
train_idx is: 7
Step 240/240, Epoch 30/30 (LogEpoch: 30), Loss: 62.9793, LR: 0.000100
Checkpoint saved: checkpoints_preprocessed/step-000240-epoch-30-loss=62.9793.pt
global_step is: 240; target_steps is: 240
06/11 [16:26:37] [34mINFO    [39m | >> [1m[[22m*[1m][22m DEBUG: End of epoch_idx ]8;id=309176;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=8582;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#368\368]8;;\
                          [1m29[22m. Current global_step = [1m240[22m,
                          target_steps = [1m240
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Target steps reached    ]8;id=193474;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=112130;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#372\372]8;;\
                          after epoch [1m30[22m. Stopping
                          training based on global_step
                          [1m(240)[22m >= target_steps [1m(240)[22m.
Training logs saved to: training_logs/training_log_20250611_162637.json
                 [34mINFO    [39m | >> [1m[[22m*[1m][22m Training completed.     ]8;id=453172;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py\train_coconut_with_preprocessed_embeddings.py]8;;\:]8;id=778542;file:///data2/xxw_data/projects/LLM/Diffusive-Latent-CoT/training/strategies/train_coconut_with_preprocessed_embeddings.py#400\400]8;;\
                          Logs saved to
                          training_logs/training_log_20250
